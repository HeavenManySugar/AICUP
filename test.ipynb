{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"processed_data.csv\")\n",
    "# Extract datetime components and join them with hyphens\n",
    "datetime_str = (data[\"Serial\"].astype(str).str[:4] + '-' +    # Year\n",
    "                   data[\"Serial\"].astype(str).str[4:6] + '-' +    # Month\n",
    "                   data[\"Serial\"].astype(str).str[6:8] + '-' +    # Day\n",
    "                   data[\"Serial\"].astype(str).str[8:12])          # Hour and Minute\n",
    "# Convert to datetime\n",
    "data['Datetime'] = pd.to_datetime(datetime_str, format='%Y-%m-%d-%H%M')\n",
    "data[\"DeviceID\"] = data[\"Serial\"].astype(str).str[12:14].astype(int)\n",
    "data['Type'] = data['DeviceID'].apply(lambda x: 1 if 1 <= x <= 14 else 2)\n",
    "# 只保留時間介於 6:00 ~ 18:00 的資料\n",
    "# data = data[(data['Datetime'].dt.hour >= 6) & (data['Datetime'].dt.hour < 18)]\n",
    "\n",
    "data['day_of_year'] = [i.dayofyear for i in data['Datetime']]\n",
    "data['month'] = [i.month for i in data['Datetime']]\n",
    "data['day'] =  [i.day for i in data['Datetime']]\n",
    "data['hour'] = [i.hour for i in data['Datetime']]\n",
    "data['minute'] = [i.minute for i in data['Datetime']]\n",
    "data[\"hhmm\"] = data[\"Serial\"].astype(str).str[8:12].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openWeather import openWeather\n",
    "data, weather_columns = openWeather(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to get the rows where the time is 08:50\n",
    "data_850 = data[(data['hour'] == 8) & (data['minute'] == 50)]\n",
    "\n",
    "# Select only the required columns\n",
    "data_850 = data_850[['DeviceID', 'day_of_year', 'Pressure(hpa)', 'WindSpeed(m/s)', 'Temperature(°C)', 'Sunlight(Lux)', 'Humidity(%)']]\n",
    "\n",
    "# Rename columns to indicate they are from 08:50\n",
    "data_850.columns = ['DeviceID', 'day_of_year', 'Pressure_850', 'WindSpeed_850', 'Temperature_850', 'Sunlight_850', 'Humidity_850']\n",
    "\n",
    "# Merge the original data with the 08:50 data\n",
    "data = pd.merge(data, data_850, on=['DeviceID', 'day_of_year'], how='left', suffixes=('', '_duplicate'))\n",
    "\n",
    "# Drop duplicate columns\n",
    "data.drop(columns=[\"Pressure(hpa)\", \"WindSpeed(m/s)\", \"Temperature(°C)\", \"Sunlight(Lux)\", \"Humidity(%)\"], inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "humidity_model = \"humidity_model.joblib\"\n",
    "pressure_model = \"pressure_model.joblib\"\n",
    "sunlight_model = \"sunlight_model.joblib\"\n",
    "temperature_model = \"temperature_model.joblib\"\n",
    "wind_speed_model = \"wind_speed_model.joblib\"\n",
    "\n",
    "X = data[\n",
    "        [\n",
    "            \"hour\",\n",
    "            \"minute\",\n",
    "            \"DeviceID\",\n",
    "            *weather_columns,\n",
    "            \"Pressure_850\",\n",
    "            \"WindSpeed_850\",\n",
    "            \"Temperature_850\",\n",
    "            \"Sunlight_850\",\n",
    "            \"Humidity_850\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "data[\"Pressure(hpa)\"] = joblib.load(pressure_model).predict(X)\n",
    "data[\"WindSpeed(m/s)\"] = joblib.load(wind_speed_model).predict(X)\n",
    "data[\"Temperature(°C)\"] = joblib.load(temperature_model).predict(X)\n",
    "data[\"Sunlight(Lux)\"] = joblib.load(sunlight_model).predict(X)\n",
    "data[\"Humidity(%)\"] = joblib.load(humidity_model).predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "\n",
    "data['month'] = data['Datetime'].dt.month\n",
    "data = encode(data, 'month', 12)\n",
    "\n",
    "# data['day'] = data['Datetime'].dt.day\n",
    "# data = encode(data, 'day', 31)\n",
    "data.drop(columns=[\"month\", \"day\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pycaret.regression import *\n",
    "\n",
    "all_Device = data['DeviceID'].unique()\n",
    "all_results = []\n",
    "final_model = {}\n",
    "\n",
    "for i in tqdm(all_Device):\n",
    "    df_subset = data[data['DeviceID'] == i]\n",
    "    \n",
    "    s = setup(df_subset, \n",
    "              use_gpu = False, \n",
    "              target = 'Power(mW)',\n",
    "              train_size = 0.95,\n",
    "              data_split_shuffle = False,\n",
    "              ignore_features = ['Datetime', 'DeviceID', 'Serial', 'yyyymmddhh'],\n",
    "              fold_strategy = \"timeseries\",\n",
    "              fold = 5,\n",
    "              verbose = False, session_id = 123, normalize = True\n",
    "             )\n",
    "    # compare all models and select best one based on MAE\n",
    "    best_model = compare_models(sort = 'MAE', verbose = True, exclude = ['lightgbm'])\n",
    "    \n",
    "    # capture the compare result grid and store best model in list\n",
    "    p = pull().iloc[0:1]\n",
    "    p['time_series'] = str(i)\n",
    "    all_results.append(p)\n",
    "    \n",
    "    # finalize model i.e. fit on entire data including test set\n",
    "    f = finalize_model(best_model)\n",
    "    \n",
    "    # attach final model to a dictionary\n",
    "    final_model[i] = f\n",
    "    \n",
    "    # save transformation pipeline and model as pickle file \n",
    "    save_model(f, model_name='trained_models/' + str(i), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results = pd.concat(all_results,axis=0)\n",
    "concat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PS01_C0Z100', 'TX01_C0Z100', 'RH01_C0Z100', 'WD01_C0Z100',\n",
      "       'WD02_C0Z100', 'WD07_C0Z100', 'WD08_C0Z100', 'PP01_C0Z100'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>DeviceID</th>\n",
       "      <th>Type</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>...</th>\n",
       "      <th>WS_Flag_鳳林生豐站</th>\n",
       "      <th>WD_鳳林生豐站</th>\n",
       "      <th>WD_Flag_鳳林生豐站</th>\n",
       "      <th>Ts_鳳林生豐站</th>\n",
       "      <th>Ts_Flag_鳳林生豐站</th>\n",
       "      <th>SWC_鳳林生豐站</th>\n",
       "      <th>SWC_Flag_鳳林生豐站</th>\n",
       "      <th>CO2_Flag_鳳林生豐站</th>\n",
       "      <th>H_Flag_鳳林生豐站</th>\n",
       "      <th>LE_Flag_鳳林生豐站</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>20240117090001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-17 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>20240117091001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-17 09:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>20240117092001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-17 09:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20240117093001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-17 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>20240117094001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-17 09:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.3905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9307</th>\n",
       "      <td>20241002161012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-02 16:10:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>20241002162012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-02 16:20:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9309</th>\n",
       "      <td>20241002163012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-02 16:30:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>20241002164012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-02 16:40:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>20241002165012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-02 16:50:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9600 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Serial  Power(mW)            Datetime  DeviceID  Type  \\\n",
       "96    20240117090001        NaN 2024-01-17 09:00:00         1     1   \n",
       "97    20240117091001        NaN 2024-01-17 09:10:00         1     1   \n",
       "98    20240117092001        NaN 2024-01-17 09:20:00         1     1   \n",
       "99    20240117093001        NaN 2024-01-17 09:30:00         1     1   \n",
       "100   20240117094001        NaN 2024-01-17 09:40:00         1     1   \n",
       "...              ...        ...                 ...       ...   ...   \n",
       "9307  20241002161012        NaN 2024-10-02 16:10:00        12     1   \n",
       "9308  20241002162012        NaN 2024-10-02 16:20:00        12     1   \n",
       "9309  20241002163012        NaN 2024-10-02 16:30:00        12     1   \n",
       "9310  20241002164012        NaN 2024-10-02 16:40:00        12     1   \n",
       "9311  20241002165012        NaN 2024-10-02 16:50:00        12     1   \n",
       "\n",
       "      day_of_year  month  day  hour  minute  ...  WS_Flag_鳳林生豐站  WD_鳳林生豐站  \\\n",
       "96             17      1   17     9       0  ...            0.0   182.460   \n",
       "97             17      1   17     9      10  ...            0.0   182.460   \n",
       "98             17      1   17     9      20  ...            0.0   189.056   \n",
       "99             17      1   17     9      30  ...            0.0   189.056   \n",
       "100            17      1   17     9      40  ...            0.0   189.056   \n",
       "...           ...    ...  ...   ...     ...  ...            ...       ...   \n",
       "9307          276     10    2    16      10  ...            NaN       NaN   \n",
       "9308          276     10    2    16      20  ...            NaN       NaN   \n",
       "9309          276     10    2    16      30  ...            NaN       NaN   \n",
       "9310          276     10    2    16      40  ...            NaN       NaN   \n",
       "9311          276     10    2    16      50  ...            NaN       NaN   \n",
       "\n",
       "      WD_Flag_鳳林生豐站  Ts_鳳林生豐站  Ts_Flag_鳳林生豐站  SWC_鳳林生豐站  SWC_Flag_鳳林生豐站  \\\n",
       "96              0.0    16.986            0.0    33.3833             0.0   \n",
       "97              0.0    16.986            0.0    33.3833             0.0   \n",
       "98              0.0    17.065            0.0    33.3905             0.0   \n",
       "99              0.0    17.065            0.0    33.3905             0.0   \n",
       "100             0.0    17.065            0.0    33.3905             0.0   \n",
       "...             ...       ...            ...        ...             ...   \n",
       "9307            NaN       NaN            NaN        NaN             NaN   \n",
       "9308            NaN       NaN            NaN        NaN             NaN   \n",
       "9309            NaN       NaN            NaN        NaN             NaN   \n",
       "9310            NaN       NaN            NaN        NaN             NaN   \n",
       "9311            NaN       NaN            NaN        NaN             NaN   \n",
       "\n",
       "      CO2_Flag_鳳林生豐站  H_Flag_鳳林生豐站  LE_Flag_鳳林生豐站  \n",
       "96               1.0           0.0            1.0  \n",
       "97               1.0           0.0            1.0  \n",
       "98               2.0           0.0            2.0  \n",
       "99               2.0           0.0            2.0  \n",
       "100              2.0           0.0            2.0  \n",
       "...              ...           ...            ...  \n",
       "9307             NaN           NaN            NaN  \n",
       "9308             NaN           NaN            NaN  \n",
       "9309             NaN           NaN            NaN  \n",
       "9310             NaN           NaN            NaN  \n",
       "9311             NaN           NaN            NaN  \n",
       "\n",
       "[9600 rows x 90 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openWeather import openWeather\n",
    "\n",
    "upload_data = pd.read_csv('upload(no answer).csv')\n",
    "# rename columns\n",
    "upload_data.columns = [\"Serial\", \"Power(mW)\"]\n",
    "# Extract datetime components and join them with hyphens\n",
    "datetime_str = (upload_data[\"Serial\"].astype(str).str[:4] + '-' +    # Year\n",
    "                   upload_data[\"Serial\"].astype(str).str[4:6] + '-' +    # Month\n",
    "                   upload_data[\"Serial\"].astype(str).str[6:8] + '-' +    # Day\n",
    "                   upload_data[\"Serial\"].astype(str).str[8:12])          # Hour and Minute\n",
    "# Convert to datetime\n",
    "upload_data['Datetime'] = pd.to_datetime(datetime_str, format='%Y-%m-%d-%H%M')\n",
    "upload_data[\"DeviceID\"] = upload_data[\"Serial\"].astype(str).str[12:14].astype(int)\n",
    "upload_data['Type'] = upload_data['DeviceID'].apply(lambda x: 1 if 1 <= x <= 14 else 2)\n",
    "\n",
    "upload_data['day_of_year'] = [i.dayofyear for i in upload_data['Datetime']]\n",
    "upload_data['month'] = [i.month for i in upload_data['Datetime']]\n",
    "upload_data['day'] =  [i.day for i in upload_data['Datetime']]\n",
    "upload_data['hour'] = [i.hour for i in upload_data['Datetime']]\n",
    "upload_data['minute'] = [i.minute for i in upload_data['Datetime']]\n",
    "upload_data[\"hhmm\"] = upload_data[\"Serial\"].astype(str).str[8:12].astype(int)\n",
    "\n",
    "# weather data\n",
    "upload_data, weather_columns = openWeather(upload_data)\n",
    "upload_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PS01_C0Z100', 'TX01_C0Z100', 'RH01_C0Z100', 'WD01_C0Z100',\n",
      "       'WD02_C0Z100', 'WD07_C0Z100', 'WD08_C0Z100', 'PP01_C0Z100'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 打開參考資料\n",
    "SourceData = pd.read_csv(\"processed_data.csv\")\n",
    "SourceData, weather_columns = openWeather(SourceData)\n",
    "SourceData[\"Datetime\"] = pd.to_datetime(\n",
    "    SourceData[\"Serial\"].astype(str).str[:12], format=\"%Y%m%d%H%M\"\n",
    ")\n",
    "SourceData[\"DeviceID\"] = SourceData[\"Serial\"].astype(str).str[12:14].astype(int)\n",
    "SourceData[\"day_of_year\"] = [i.dayofyear for i in SourceData[\"Datetime\"]]\n",
    "SourceData[\"hour\"] = [i.hour for i in SourceData[\"Datetime\"]]\n",
    "SourceData[\"minute\"] = [i.minute for i in SourceData[\"Datetime\"]]\n",
    "# Filter data to get the rows where the time is 08:50\n",
    "data_850 = SourceData[(SourceData[\"hour\"] == 8) & (SourceData[\"minute\"] == 50)]\n",
    "\n",
    "# Select only the required columns\n",
    "data_850 = data_850[\n",
    "    [\n",
    "        \"DeviceID\",\n",
    "        \"day_of_year\",\n",
    "        \"Pressure(hpa)\",\n",
    "        \"WindSpeed(m/s)\",\n",
    "        \"Temperature(°C)\",\n",
    "        \"Sunlight(Lux)\",\n",
    "        \"Humidity(%)\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Rename columns to indicate they are from 08:50\n",
    "data_850.columns = [\n",
    "    \"DeviceID\",\n",
    "    \"day_of_year\",\n",
    "    \"Pressure_850\",\n",
    "    \"WindSpeed_850\",\n",
    "    \"Temperature_850\",\n",
    "    \"Sunlight_850\",\n",
    "    \"Humidity_850\",\n",
    "]\n",
    "\n",
    "upload_data = pd.merge(\n",
    "    upload_data,\n",
    "    data_850,\n",
    "    on=[\"DeviceID\", \"day_of_year\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_duplicate\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "humidity_model = \"humidity_model.joblib\"\n",
    "pressure_model = \"pressure_model.joblib\"\n",
    "sunlight_model = \"sunlight_model.joblib\"\n",
    "temperature_model = \"temperature_model.joblib\"\n",
    "wind_speed_model = \"wind_speed_model.joblib\"\n",
    "\n",
    "X = upload_data[\n",
    "    [\n",
    "        \"hour\",\n",
    "        \"minute\",\n",
    "        \"DeviceID\",\n",
    "        *weather_columns,\n",
    "        \"Pressure_850\",\n",
    "        \"WindSpeed_850\",\n",
    "        \"Temperature_850\",\n",
    "        \"Sunlight_850\",\n",
    "        \"Humidity_850\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "upload_data[\"Pressure(hpa)\"] = joblib.load(pressure_model).predict(X)\n",
    "upload_data[\"WindSpeed(m/s)\"] = joblib.load(wind_speed_model).predict(X)\n",
    "upload_data[\"Temperature(°C)\"] = joblib.load(temperature_model).predict(X)\n",
    "upload_data[\"Sunlight(Lux)\"] = joblib.load(sunlight_model).predict(X)\n",
    "upload_data[\"Humidity(%)\"] = joblib.load(humidity_model).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "\n",
    "upload_data['month'] = upload_data['Datetime'].dt.month\n",
    "upload_data = encode(upload_data, 'month', 12)\n",
    "\n",
    "# data['day'] = data['Datetime'].dt.day\n",
    "# data = encode(data, 'day', 31)\n",
    "upload_data.drop(columns=[\"month\", \"day\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:05<00:00,  2.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>DeviceID</th>\n",
       "      <th>Type</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>hhmm</th>\n",
       "      <th>yyyymmddhh</th>\n",
       "      <th>PS01_C0Z100</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunlight_850</th>\n",
       "      <th>Humidity_850</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240117090001</td>\n",
       "      <td>2024-01-17 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>2024011709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20943.169922</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1014.890320</td>\n",
       "      <td>0.595301</td>\n",
       "      <td>20.928242</td>\n",
       "      <td>19241.083984</td>\n",
       "      <td>97.664009</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>89.703099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240117091001</td>\n",
       "      <td>2024-01-17 09:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>910</td>\n",
       "      <td>2024011709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20943.169922</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1014.883301</td>\n",
       "      <td>0.593254</td>\n",
       "      <td>21.432674</td>\n",
       "      <td>20886.824219</td>\n",
       "      <td>96.213249</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>117.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240117092001</td>\n",
       "      <td>2024-01-17 09:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>920</td>\n",
       "      <td>2024011709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20943.169922</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1017.393005</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>21.577967</td>\n",
       "      <td>21286.353516</td>\n",
       "      <td>96.592651</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>109.526801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240117093001</td>\n",
       "      <td>2024-01-17 09:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>930</td>\n",
       "      <td>2024011709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20943.169922</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1017.921814</td>\n",
       "      <td>0.508208</td>\n",
       "      <td>21.837189</td>\n",
       "      <td>24639.152344</td>\n",
       "      <td>95.871498</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>159.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240117094001</td>\n",
       "      <td>2024-01-17 09:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>940</td>\n",
       "      <td>2024011709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20943.169922</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1015.586182</td>\n",
       "      <td>0.507348</td>\n",
       "      <td>22.395863</td>\n",
       "      <td>26097.015625</td>\n",
       "      <td>94.647408</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>183.764000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Serial            Datetime  DeviceID  Type  day_of_year  hour  \\\n",
       "0  20240117090001 2024-01-17 09:00:00         1     1           17     9   \n",
       "1  20240117091001 2024-01-17 09:10:00         1     1           17     9   \n",
       "2  20240117092001 2024-01-17 09:20:00         1     1           17     9   \n",
       "3  20240117093001 2024-01-17 09:30:00         1     1           17     9   \n",
       "4  20240117094001 2024-01-17 09:40:00         1     1           17     9   \n",
       "\n",
       "   minute  hhmm  yyyymmddhh  PS01_C0Z100  ...  Sunlight_850  Humidity_850  \\\n",
       "0       0   900  2024011709          NaN  ...  20943.169922         100.0   \n",
       "1      10   910  2024011709          NaN  ...  20943.169922         100.0   \n",
       "2      20   920  2024011709          NaN  ...  20943.169922         100.0   \n",
       "3      30   930  2024011709          NaN  ...  20943.169922         100.0   \n",
       "4      40   940  2024011709          NaN  ...  20943.169922         100.0   \n",
       "\n",
       "   Pressure(hpa)  WindSpeed(m/s)  Temperature(°C)  Sunlight(Lux)  Humidity(%)  \\\n",
       "0    1014.890320        0.595301        20.928242   19241.083984    97.664009   \n",
       "1    1014.883301        0.593254        21.432674   20886.824219    96.213249   \n",
       "2    1017.393005        0.509767        21.577967   21286.353516    96.592651   \n",
       "3    1017.921814        0.508208        21.837189   24639.152344    95.871498   \n",
       "4    1015.586182        0.507348        22.395863   26097.015625    94.647408   \n",
       "\n",
       "   month_sin  month_cos  prediction_label  \n",
       "0        0.5   0.866025         89.703099  \n",
       "1        0.5   0.866025        117.035100  \n",
       "2        0.5   0.866025        109.526801  \n",
       "3        0.5   0.866025        159.461900  \n",
       "4        0.5   0.866025        183.764000  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from pycaret.regression import load_model, predict_model\n",
    "all_Device = upload_data['DeviceID'].unique()\n",
    "all_score_df = []\n",
    "\n",
    "for i in tqdm(all_Device):\n",
    "    df_subset = upload_data[upload_data['DeviceID'] == i]\n",
    "    df_subset = df_subset.drop(columns=[\"Power(mW)\"])\n",
    "    l = load_model('trained_models/' + str(i), verbose=False)\n",
    "    p = predict_model(l, data=df_subset)\n",
    "    p['DeviceID'] = i\n",
    "    all_score_df.append(p)\n",
    "\n",
    "concat_df = pd.concat(all_score_df, axis=0)\n",
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df[\"prediction_label\"] = np.maximum(concat_df[\"prediction_label\"], 0)\n",
    "concat_df[\"prediction_label\"] = np.round(concat_df[\"prediction_label\"], 2)\n",
    "output = pd.DataFrame({\"序號\": concat_df[\"Serial\"], \"答案\": concat_df[\"prediction_label\"]})\n",
    "output.to_csv(\"predictions.csv\", index=False, encoding=\"utf-8\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 9600]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(y_pred)\n\u001b[0;32m---> 12\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, y_pred))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Absolute Error (MAE): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/AICUP/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/AICUP/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:207\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    144\u001b[0m     {\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m ):\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    211\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/AICUP/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/AICUP/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 9600]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = concat_df[\"prediction_label\"]\n",
    "processed_data = pd.read_csv(\"processed_data.csv\")\n",
    "y_test = processed_data.loc[processed_data[\"Serial\"].isin(concat_df[\"Serial\"])][\n",
    "    \"Power(mW)\"\n",
    "]\n",
    "# Handle NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "y_pred = np.nan_to_num(y_pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "score = sum(abs(y_test - y_pred))\n",
    "print(f\"Score: {score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
